{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练及测试说明\n",
    "首先运行模型 `NeuralNetwork` 类模块代码，完成模型构建，调用该类时输入：\\\n",
    "input_size：输入层维度\\\n",
    "hidden_size_1：第一层隐藏层维度\\\n",
    "hidden_size_2：第二层隐藏层维度\\\n",
    "output_size：输出层维度（针对mnist数据集，默认10）\\\n",
    "lambda_reg：L2正则化系数 \\\n",
    "activation：激活函数（在该python模块中给了sigmoid、relu和tanh三种激活函数可以选择）\n",
    "\n",
    "#### 训练部分\n",
    "把交叉熵损失和L2正则化损失函数整合到 `train` 函数中，实现了计算交叉熵损失以及L2正则化，训练中运用小批量SGD优化器，设置每个批次600个数据，每轮训练学习率下降为原本的97%\n",
    "\n",
    "根据代码测试运行，本实验将训练轮数设置为25次。得到的每轮的训练结果中，根据验证集上的准确度得分保存最优模型参数，输出的结果为最优权重参数和最优准确率得分，并可视化每轮训练的测试集和验证集上的损失、验证集上的准确率\n",
    "\n",
    "### 参数查找部分\n",
    "`grid_search` 函数针对学习率、L2正则化系数以及隐藏层大小进行网格搜索，以获得最优超参数组合\n",
    "\n",
    "并可视化神经网络的最优参数\n",
    "\n",
    "之后直接调用该函数进行包含参数查找的模型训练\n",
    "\n",
    "### 测试部分\n",
    "调用已训练好的最优权重参数直接输入给神经网络模型，前向传播输出结果计算准确率，即为测试集上的测试效果；直接运行该模块即可"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
